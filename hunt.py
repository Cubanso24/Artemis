#!/usr/bin/env python3
"""
Artemis Threat Hunting - Network-Focused Hunt
Optimized for environments with Zeek/Suricata network data.
"""

import os
import sys
import json
from datetime import datetime
from pathlib import Path

from artemis.meta_learner.coordinator import MetaLearnerCoordinator
from artemis.integrations.data_pipeline import DataPipeline
from artemis.models.network_state import NetworkState
from artemis.plugins.network_mapper import NetworkMapperPlugin


class HuntAnalyzer:
    """Analyzes and displays hunt results in detail."""

    def __init__(self, output_dir: str = "hunt_results"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        self.hunt_timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    def display_banner(self):
        """Display Artemis banner."""
        print("\n" + "=" * 80)
        print("  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—")
        print(" â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•")
        print(" â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—")
        print(" â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ•â•â•â•â–ˆâ–ˆâ•‘")
        print(" â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘")
        print(" â•šâ•â•  â•šâ•â•â•šâ•â•  â•šâ•â•   â•šâ•â•   â•šâ•â•â•â•â•â•â•â•šâ•â•     â•šâ•â•â•šâ•â•â•šâ•â•â•â•â•â•â•")
        print("           Multi-Agent Threat Hunting System")
        print("=" * 80)

    def print_section(self, title: str):
        """Print a section header."""
        print(f"\n{'â”€' * 80}")
        print(f"  {title}")
        print(f"{'â”€' * 80}")

    def print_network_state(self, state: NetworkState):
        """Display the current network state being analyzed."""
        self.print_section("ğŸ“Š NETWORK STATE ANALYSIS")

        print(f"\nğŸ” Network Metrics:")
        print(f"  â€¢ Connection Count: {state.traffic_metrics.connection_count}")
        print(f"  â€¢ DNS Queries: {state.traffic_metrics.dns_queries}")
        total_bytes = state.traffic_metrics.total_bytes_in + state.traffic_metrics.total_bytes_out
        print(f"  â€¢ Total Data Transfer: {total_bytes / 1024 / 1024:.2f} MB")
        print(f"  â€¢ Unique Destinations: {state.traffic_metrics.unique_destinations}")
        print(f"  â€¢ Failed Connections: {state.traffic_metrics.failed_connections}")

        print(f"\nâ° Time Context:")
        print(f"  â€¢ Hour of Day: {state.time_features.hour_of_day}:00")
        print(f"  â€¢ Day of Week: {['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'][state.time_features.day_of_week]}")
        print(f"  â€¢ Is Business Hours: {'Yes' if state.time_features.is_business_hours else 'No'}")
        print(f"  â€¢ Is Weekend: {'Yes' if state.time_features.is_weekend else 'No'}")

        if state.alert_history.total_alerts_24h > 0:
            print(f"\nâš ï¸  Recent Alerts: {state.alert_history.total_alerts_24h} in last 24h")

    def print_hypotheses(self, hypotheses: list):
        """Display threat hypotheses generated."""
        if not hypotheses:
            print("\nâœ“ No immediate threat indicators detected")
            return

        self.print_section("ğŸ¯ THREAT HYPOTHESES GENERATED")

        for i, hyp in enumerate(hypotheses, 1):
            print(f"\n[{i}] {hyp.description}")
            print(f"    Type: {hyp.hypothesis_type}")
            print(f"    Confidence: {hyp.initial_confidence:.2f}")
            print(f"    Priority: {hyp.priority}")
            if hyp.indicators:
                print(f"    Indicators: {', '.join(hyp.indicators[:3])}")

    def print_agent_selection(self, selected_agents: list):
        """Display which agents were selected and why."""
        self.print_section("ğŸ¤– AGENT DEPLOYMENT")

        print(f"\nDeploying {len(selected_agents)} specialized hunting agents:\n")

        agent_descriptions = {
            "ReconnaissanceHunter": "Scanning for port scans, network sweeps, DNS recon",
            "C2Hunter": "Detecting beaconing, DGA domains, suspicious callbacks",
            "LateralMovementHunter": "Tracking SMB/RDP lateral movement patterns",
            "CollectionExfiltrationHunter": "Monitoring large data transfers and exfil",
            "InitialAccessHunter": "Analyzing authentication patterns and access",
            "ExecutionPersistenceHunter": "Checking process execution and persistence",
            "CredentialAccessHunter": "Detecting credential theft attempts",
            "DefenseEvasionHunter": "Finding evasion techniques and anti-forensics",
            "ImpactHunter": "Identifying destructive activities and impacts"
        }

        for agent in selected_agents:
            agent_name = agent.__class__.__name__
            desc = agent_descriptions.get(agent_name, "Specialized threat detection")
            print(f"  âœ“ {agent_name:30s} â†’ {desc}")

    def print_findings(self, assessment: dict):
        """Display findings from the hunt assessment."""
        self.print_section("ğŸ” HUNTING RESULTS")

        total_findings = assessment.get('total_findings', 0)

        if total_findings == 0:
            print("\nâœ“ No threats detected - Network appears clean")
            return

        print(f"\nâš ï¸  Found {total_findings} potential threats:\n")

        # Group by severity using agent outputs
        critical = []
        high = []
        medium = []
        low = []

        for agent_output in assessment.get('agent_outputs', []):
            agent_name = agent_output['agent_name']
            severity = agent_output.get('severity', 'low').upper()
            confidence = agent_output.get('confidence', 0)

            for finding in agent_output.get('findings', []):
                entry = (agent_name, finding, confidence)
                if severity == "CRITICAL":
                    critical.append(entry)
                elif severity == "HIGH":
                    high.append(entry)
                elif severity == "MEDIUM":
                    medium.append(entry)
                else:
                    low.append(entry)

        # Display findings by severity
        for severity_name, findings_list, emoji in [
            ("CRITICAL", critical, "ğŸ”´"),
            ("HIGH", high, "ğŸŸ "),
            ("MEDIUM", medium, "ğŸŸ¡"),
            ("LOW", low, "ğŸ”µ")
        ]:
            if findings_list:
                print(f"\n{emoji} {severity_name} Severity ({len(findings_list)} findings):")
                for agent_name, finding, confidence in findings_list:
                    print(f"\n  [{agent_name}] {finding.get('activity_type', 'Unknown')}")
                    print(f"  â””â”€ {finding.get('description', 'No description')}")
                    print(f"  â””â”€ Confidence: {confidence:.2f}")
                    if finding.get('mitre_techniques'):
                        print(f"  â””â”€ MITRE: {', '.join(finding['mitre_techniques'])}")
                    if finding.get('affected_assets'):
                        print(f"  â””â”€ Affected: {', '.join(finding['affected_assets'][:3])}")

    def print_aggregated_results(self, assessment: dict):
        """Display meta-learner's aggregated assessment."""
        self.print_section("ğŸ§  META-LEARNER ANALYSIS")

        print(f"\nğŸ“ˆ Overall Threat Assessment:")
        print(f"  â€¢ Total Findings: {assessment.get('total_findings', 0)}")
        print(f"  â€¢ Overall Confidence: {assessment.get('final_confidence', 0):.2f}")
        print(f"  â€¢ Corroborating Agents: {assessment.get('corroborating_agents', 0)}")
        print(f"  â€¢ Alert Level: {assessment.get('alert_level', 'none')}")

        if assessment.get('mitre_techniques'):
            print(f"\nğŸ¯ MITRE ATT&CK Techniques Detected:")
            for technique in assessment['mitre_techniques']:
                print(f"  â€¢ {technique}")

        if assessment.get('recommendations'):
            print(f"\nğŸ“‹ Recommendations:")
            for rec in assessment['recommendations']:
                print(f"  â€¢ {rec}")

    def save_results(self, assessment: dict, network_state: NetworkState):
        """Save hunt results to JSON for later analysis."""
        output_file = self.output_dir / f"hunt_{self.hunt_timestamp}.json"

        # Serialize severity enum if present
        severity = assessment.get('severity', 'low')
        if hasattr(severity, 'value'):
            severity = severity.value

        hunt_data = {
            "timestamp": self.hunt_timestamp,
            "network_state": {
                "connection_count": network_state.traffic_metrics.connection_count,
                "dns_queries": network_state.traffic_metrics.dns_queries,
                "total_bytes": network_state.traffic_metrics.total_bytes_in + network_state.traffic_metrics.total_bytes_out,
                "unique_destinations": network_state.traffic_metrics.unique_destinations,
                "failed_connections": network_state.traffic_metrics.failed_connections,
                "is_business_hours": network_state.time_features.is_business_hours,
            },
            "total_findings": assessment.get('total_findings', 0),
            "final_confidence": assessment.get('final_confidence', 0),
            "severity": severity,
            "alert_level": assessment.get('alert_level', 'none'),
            "mitre_techniques": assessment.get('mitre_techniques', []),
            "agent_outputs": assessment.get('agent_outputs', []),
            "recommendations": assessment.get('recommendations', [])
        }

        with open(output_file, 'w') as f:
            json.dump(hunt_data, f, indent=2, default=str)

        print(f"\nğŸ’¾ Results saved to: {output_file}")

        # Also save a summary
        summary_file = self.output_dir / "latest_hunt.txt"
        with open(summary_file, 'w') as f:
            f.write(f"Artemis Hunt Summary - {self.hunt_timestamp}\n")
            f.write("=" * 80 + "\n\n")
            f.write(f"Total Findings: {assessment.get('total_findings', 0)}\n")
            f.write(f"Overall Confidence: {assessment.get('final_confidence', 0):.2f}\n")
            f.write(f"Alert Level: {assessment.get('alert_level', 'none')}\n")
            f.write(f"Agents Deployed: {assessment.get('agent_count', 0)}\n\n")

            for agent_output in assessment.get('agent_outputs', []):
                findings = agent_output.get('findings', [])
                if findings:
                    f.write(f"\n{agent_output['agent_name']}:\n")
                    for finding in findings:
                        f.write(f"  - {finding.get('activity_type', 'Unknown')} ({finding.get('description', '')})\n")

        return output_file


def main():
    """Run a network-focused threat hunt."""

    analyzer = HuntAnalyzer()
    analyzer.display_banner()

    print("\nğŸš€ Initializing Artemis Threat Hunting System...")

    # Check Splunk credentials
    host = os.getenv('SPLUNK_HOST', '10.25.11.86')
    token = os.getenv('SPLUNK_TOKEN')
    username = os.getenv('SPLUNK_USERNAME')
    password = os.getenv('SPLUNK_PASSWORD')

    if not token and not (username and password):
        print("\nâŒ ERROR: Splunk credentials not set!")
        print("   Set SPLUNK_TOKEN or SPLUNK_USERNAME/SPLUNK_PASSWORD")
        sys.exit(1)

    # Initialize data pipeline (Splunk only, no Security Onion for now)
    print("ğŸ“¡ Connecting to data sources...")
    from artemis.integrations.data_pipeline import DataSourceConfig

    config = DataSourceConfig(
        splunk_host=host,
        splunk_port=8089,
        splunk_username=username if not token else "",
        splunk_password=password if not token else "",
        splunk_token=token if token else ""
    )

    pipeline = DataPipeline(config)

    # Initialize meta-learner coordinator
    print("ğŸ§  Initializing Meta-Learner Coordinator...")
    coordinator = MetaLearnerCoordinator()

    # Collect network data
    analyzer.print_section("ğŸ“¡ COLLECTING NETWORK DATA")
    print("\nQuerying Splunk for network telemetry...")
    print("  â€¢ Time range: Last 1 hour")
    print("  â€¢ Sources: Zeek (conn, dns, http, ssl), Suricata alerts")

    hunting_data = pipeline.collect_hunting_data(time_range="-1h")

    print(f"\nâœ“ Collected {sum(len(v) for v in hunting_data.values())} total events")
    print(f"  â€¢ Network Connections: {len(hunting_data.get('network_connections', []))}")
    print(f"  â€¢ DNS Queries: {len(hunting_data.get('dns_queries', []))}")

    # Create network state for display purposes
    network_state = NetworkState.from_data(hunting_data)
    analyzer.print_network_state(network_state)

    # Run the hunt
    analyzer.print_section("ğŸ¯ LAUNCHING THREAT HUNT")
    print("\nMeta-learner is analyzing the network state...")
    print("This may take 30-60 seconds...\n")

    # coordinator.hunt() signature: hunt(data, initial_signals=None, context_data=None)
    # It creates NetworkState internally from context_data
    hunt_result = coordinator.hunt(
        data=hunting_data,
        initial_signals=None,
        context_data=None
    )

    # Update network mapper
    print("\nğŸ—ºï¸  Updating network map...")
    mapper = NetworkMapperPlugin({'output_dir': 'network_maps'})
    mapper.initialize()
    map_result = mapper.execute(
        network_connections=hunting_data.get('network_connections', []),
        dns_queries=hunting_data.get('dns_queries', []),
    )
    mapper.save_map()
    print(f"  â€¢ Mapped {map_result['total_nodes']} nodes across sensors: {', '.join(map_result.get('sensors', []))}")

    # Display findings
    analyzer.print_findings(hunt_result)

    # Display aggregated results
    analyzer.print_aggregated_results(hunt_result)

    # Save results
    output_file = analyzer.save_results(hunt_result, network_state)

    # Final summary
    analyzer.print_section("âœ… HUNT COMPLETE")

    total_findings = hunt_result.get('total_findings', 0)

    if total_findings > 0:
        print(f"\nâš ï¸  Detected {total_findings} potential threats requiring investigation")
        print(f"\nğŸ“‹ Next Steps:")
        print(f"  1. Review the findings above prioritized by severity")
        print(f"  2. Investigate affected assets and network flows")
        print(f"  3. Check {output_file} for detailed JSON output")
        print(f"  4. Re-run with different time ranges: hunt.py --time-range '-24h'")
    else:
        print(f"\nâœ“ No threats detected in this hunt")
        print(f"\nğŸ’¡ Tips for improving detection:")
        print(f"  â€¢ Increase time range: hunt.py --time-range '-24h'")
        print(f"  â€¢ Hunt during high activity periods")
        print(f"  â€¢ Enable Windows log collection for host-based detection")

    print("\n" + "=" * 80 + "\n")


if __name__ == "__main__":
    # Add argument parsing for time range
    import argparse
    parser = argparse.ArgumentParser(description="Artemis Threat Hunting")
    parser.add_argument('--time-range', default='-1h', help='Splunk time range (e.g., -1h, -24h)')
    args = parser.parse_args()

    # For now, use default time range (will enhance later)
    main()
